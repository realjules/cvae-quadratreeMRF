{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":323641,"sourceType":"datasetVersion","datasetId":136436},{"sourceId":277914,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":238030,"modelId":259698},{"sourceId":277925,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":238040,"modelId":259708}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NEW CODE","metadata":{}},{"cell_type":"code","source":"# CRFNet-RS: Semantic Segmentation for Remote Sensing Images\n\n# Cell 1: Setup Environment\nimport os\nimport sys\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport random\nfrom tqdm.notebook import tqdm\nfrom glob import glob\nimport time\nfrom datetime import datetime\nfrom skimage import io\n\n# Set random seeds for reproducibility\nrandom.seed(42)\ntorch.manual_seed(42)\nnp.random.seed(42)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(42)\n\n# Clone the repository\n!git clone https://github.com/Ayana-Inria/CRFNet-RS.git\nsys.path.append('./CRFNet-RS')\n\n# Install dependencies\n!pip install -r ./CRFNet-RS/requirements.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 2: Fix Imports in main.py\n# Fix the unet import issue\nwith open('./CRFNet-RS/main.py', 'r') as file:\n    content = file.read()\n\n# Replace the incorrect import\nfixed_content = content.replace('from net.unet import *', '# from net.unet import *')\n\nwith open('./CRFNet-RS/main.py', 'w') as file:\n    file.write(fixed_content)\n\nprint(\"Fixed import in main.py\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 3: Configure Paths and Parameters\nimport os\nfrom datetime import datetime\n\n# Configuration parameters\nWINDOW_SIZE = (256, 256)  # Patch size\nSTRIDE = 32  # Stride for testing inference\nIN_CHANNELS = 3  # Number of input channels (RGB/IRRG)\nBATCH_SIZE = 10  # Mini-batch size\nEPOCHS = 50  # Number of training epochs\nSAVE_EPOCH = 10  # Save model every N epochs\nBASE_LR = 0.01  # Base learning rate\nWEIGHT_DECAY = 0.0005  # Weight decay for optimizer\n\n# Dataset parameters\nDATASET_TYPE = \"Vaihingen\"  # Options: \"Vaihingen\" or \"Potsdam\"\nGT_TYPE = \"conncomp\"  # Options: \"full\", \"conncomp\", \"ero\"\nERO_DISK_SIZE = 8  # Size of erosion disk for ground truth processing\n\n# Organize folders\nDATA_ROOT = \"/kaggle/input/potsdamvaihingen/\"  # Input data path\nOUTPUT_ROOT = \"/kaggle/working/\"  # Working directory for outputs\nWORKING_DATA_ROOT = \"/kaggle/working/data\"  # Working directory for data processing\n\n# Create necessary directories\nos.makedirs(OUTPUT_ROOT, exist_ok=True)\nos.makedirs(WORKING_DATA_ROOT, exist_ok=True)\nos.makedirs(f\"{WORKING_DATA_ROOT}/top\", exist_ok=True)\nos.makedirs(f\"{WORKING_DATA_ROOT}/gt\", exist_ok=True)\nos.makedirs(f\"{WORKING_DATA_ROOT}/gt_eroded\", exist_ok=True)\n\n# Experiment naming\nEXPERIMENT_NAME = f\"CRFNet_{DATASET_TYPE}_{GT_TYPE}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\nos.makedirs(f\"{OUTPUT_ROOT}/{EXPERIMENT_NAME}\", exist_ok=True)\n\n# Set paths based on dataset\nif DATASET_TYPE == \"Vaihingen\":\n    train_ids = ['1', '3', '23', '26', '7', '11', '13', '28', '17', '32', '34', '37']\n    test_ids = ['5', '15', '21', '30']\nelse:  # Potsdam\n    train_ids = ['3_11', '4_11', '5_10', '6_7', '6_8', '6_9', '7_7', '7_8', '7_9', '7_10']\n    test_ids = ['3_12', '4_10', '4_12', '5_11', '6_12']\n\n# # Data file paths\n# DATA_FILES = f\"{DATA_ROOT}/ISPRS_semantic_labeling_Vaihingen/top/top_mosaic_09cm_area{{id}}.tif\"\n# LABEL_FILES = f\"{DATA_ROOT}/ISPRS_semantic_labeling_Vaihingen/gts_for_participants/top_mosaic_09cm_area{{id}}.tif\"\n# ERODED_FILES = f\"{DATA_ROOT}/5_Labels_for_participants_no_Boundary/5_Labels_for_participants_no_Boundary/top_potsdam_{{id}}_label_noBoundary.tif\"\n\n# For Vaihingen dataset\nDATA_FILES = f\"{DATA_ROOT}/ISPRS_semantic_labeling_Vaihingen/top/top_mosaic_09cm_area{{}}.tif\"\nLABEL_FILES = f\"{DATA_ROOT}/ISPRS_semantic_labeling_Vaihingen/gts_for_participants/top_mosaic_09cm_area{{}}.tif\"\n\n# Use the original labels as \"eroded\" labels\nERODED_FILES = LABEL_FILES\n\n# Class labels\nLABELS = [\"roads\", \"buildings\", \"low veg.\", \"trees\", \"cars\", \"clutter\"]\nN_CLASSES = len(LABELS)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Open the file and fix the indentation\n!cat /kaggle/working/CRFNet-RS/utils/utils_network.py | head -90\n!sed -i '89s/^/        /' /kaggle/working/CRFNet-RS/utils/utils_network.py\nfrom net.net import CRFNet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 4: Import Required Modules\nfrom dataset.dataset import ISPRS_dataset\nfrom utils.utils_dataset import convert_from_color, convert_to_color, disk\nfrom utils.utils import metrics, sliding_window, count_sliding_window, grouper\nfrom utils.export_result import set_output_location, export_results\nfrom net.net import CRFNet\nfrom net.loss import CrossEntropy2d\nfrom skimage import io\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\n# Display dataset information\nprint(f\"Dataset: {DATASET_TYPE}\")\nprint(f\"Ground Truth Type: {GT_TYPE}\")\nprint(f\"Training on {len(train_ids)} tiles: {train_ids}\")\nprint(f\"Testing on {len(test_ids)} tiles: {test_ids}\")\nprint(f\"Using {'GPU' if torch.cuda.is_available() else 'CPU'} for computation\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 5: Initialize Model and Optimizer\n# Initialize the CRFNet model\nnet = CRFNet(n_channels=IN_CHANNELS, n_classes=N_CLASSES, bilinear=True)\n\n# Setup optimizer and learning rate scheduler\noptimizer = optim.SGD(net.parameters(), lr=BASE_LR, momentum=0.9, weight_decay=WEIGHT_DECAY)\nscheduler = optim.lr_scheduler.MultiStepLR(optimizer, [25, 35, 45], gamma=0.1)\n\n# Move model to GPU if available\nif torch.cuda.is_available():\n    net.cuda()\n    WEIGHTS = torch.ones(N_CLASSES).cuda()\nelse:\n    WEIGHTS = torch.ones(N_CLASSES)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 6: Define Training Function\ndef train_model(net, optimizer, scheduler, train_loader, epochs, save_epoch, weights, output_path):\n    \"\"\"\n    Train the CRFNet model\n    \"\"\"\n    # Import any missing modules needed for training\n    import torch.nn.functional as F\n    import cv2\n    from utils.utils_network import compute_class_weight\n    from net.train import train\n    \n    # Run the training function\n    train(net, optimizer, epochs, save_epoch, weights, train_loader, BATCH_SIZE, WINDOW_SIZE, output_path, scheduler)\n    \n    # Save final model\n    final_model_path = f'{output_path}/model_final.pth'\n    return final_model_path","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 7: Define Testing Function\ndef test_model(net, test_ids, data_files, label_files, eroded_files, labels, stride, batch_size, window_size, output_path=None):\n    \"\"\"\n    Test the model on the provided test data\n    \"\"\"\n    from net.test_network import test\n    \n    # Load test data\n    test_images = [1/255 * np.asarray(io.imread(DATA_FILES.format(id)), dtype='float32') for id in test_ids]\n    test_labels = [np.asarray(io.imread(LABEL_FILES.format(id)), dtype='uint8') for id in test_ids]\n    eroded_labels = [convert_from_color(label) for label in test_labels]\n    # test_images = [1/255 * np.asarray(io.imread(data_files.format(id)), dtype='float32') for id in test_ids]\n    # test_labels = [np.asarray(io.imread(label_files.format(id)), dtype='uint8') for id in test_ids]\n    # eroded_labels = [convert_from_color(io.imread(eroded_files.format(id))) for id in test_ids]\n    \n    # Run the test\n    acc, all_preds, all_gts = test(\n        net, test_ids, test_images, test_labels, eroded_labels, \n        labels, stride, batch_size, window_size=window_size, all=True\n    )\n    \n    # Export results\n    if output_path:\n        title = \"Quantitative results for CRFNet testing\"\n        export_results(\n            all_preds, all_gts, \n            os.path.dirname(output_path), os.path.basename(output_path),\n            confusionMat=True,\n            prodAccuracy=True,\n            averageAccuracy=True,\n            kappaCoeff=True,\n            title=title\n        )\n        \n        # Save prediction images\n        for pred, tile_id in zip(all_preds, test_ids):\n            img = convert_to_color(pred)\n            io.imsave(f\"{output_path}/segmentation_result_area{tile_id}.png\", img)\n    \n    return acc, all_preds, all_gts","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Modify the data file paths to use .format(id=...) instead\nDATA_FILES = f\"{DATA_ROOT}/ISPRS_semantic_labeling_Vaihingen/top/top_mosaic_09cm_area{{}}.tif\"\nLABEL_FILES = f\"{DATA_ROOT}/ISPRS_semantic_labeling_Vaihingen/gts_for_participants/top_mosaic_09cm_area{{}}.tif\"\nERODED_FILES = f\"{DATA_ROOT}/5_Labels_for_participants_no_Boundary/5_Labels_for_participants_no_Boundary/top_potsdam_{{}}_label_noBoundary.tif\"\n\n# Then in the dataset initialization\ntrain_set = ISPRS_dataset(\n    ids=train_ids,\n    ids_type='TRAIN',\n    gt_type=GT_TYPE,\n    gt_modification=disk(ERO_DISK_SIZE),\n    data_files=DATA_FILES,\n    label_files=LABEL_FILES,\n    window_size=WINDOW_SIZE,\n    cache=True,\n    augmentation=True\n)\n\n# Create data loader\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE)\nprint(f\"Created training loader with approximately {len(train_set) // BATCH_SIZE} batches per epoch\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def test_model(net, test_ids, data_files, label_files, eroded_files, labels, stride, batch_size, window_size, output_path=None):\n#     \"\"\"\n#     Test the model on the provided test data\n#     \"\"\"\n#     from net.test_network import test\n#     from skimage import io\n#     import numpy as np\n#     import os\n#     from utils.utils_dataset import convert_from_color\n#     from utils.export_result import export_results\n    \n#     all_preds = []\n#     all_gts = []\n    \n#     # Load test data safely with error handling\n#     test_images = []\n#     test_labels = []\n#     eroded_labels = []\n    \n#     for id in test_ids:\n#         print(f\"Loading test data for tile {id}...\")\n        \n#         # Load input image\n#         try:\n#             img = 1/255 * np.asarray(io.imread(data_files.format(id)), dtype='float32')\n#             test_images.append(img)\n#             print(f\"Image shape: {img.shape}\")\n#         except Exception as e:\n#             print(f\"Error loading image for tile {id}: {e}\")\n#             continue\n        \n#         # Load label\n#         try:\n#             label = np.asarray(io.imread(label_files.format(id)), dtype='uint8')\n#             test_labels.append(label)\n#             print(f\"Label shape: {label.shape}\")\n#         except Exception as e:\n#             print(f\"Error loading label for tile {id}: {e}\")\n#             # Remove the corresponding image\n#             test_images.pop()\n#             continue\n        \n#         # Load eroded label\n#         try:\n#             eroded = io.imread(eroded_files.format(id))\n#             print(f\"Eroded label initial shape: {eroded.shape}\")\n            \n#             # Check if the image is already a 2D array (grayscale)\n#             if len(eroded.shape) == 2:\n#                 # This is already a label map, no need to convert from color\n#                 eroded_label = eroded\n#             else:\n#                 # This is an RGB image, convert from color\n#                 eroded_label = convert_from_color(eroded)\n                \n#             eroded_labels.append(eroded_label)\n#             print(f\"Processed eroded label shape: {eroded_label.shape}\")\n#         except Exception as e:\n#             print(f\"Error loading eroded label for tile {id}: {e}\")\n#             # Remove the corresponding image and label\n#             test_images.pop()\n#             test_labels.pop()\n#             continue\n    \n#     # Make sure we have data to test\n#     if not test_images:\n#         print(\"No valid test data found. Check your file paths and image formats.\")\n#         return 0, [], []\n    \n#     # Update test_ids to only include those we successfully loaded\n#     valid_test_ids = test_ids[:len(test_images)]\n#     print(f\"Testing on {len(valid_test_ids)} valid tiles: {valid_test_ids}\")\n    \n#     # Run the test\n#     acc, all_preds, all_gts = test(\n#         net, valid_test_ids, test_images, test_labels, eroded_labels, \n#         labels, stride, batch_size, window_size=window_size, all=True\n#     )\n    \n#     # Export results\n#     if output_path and all_preds:\n#         title = \"Quantitative results for CRFNet testing\"\n#         export_results(\n#             all_preds, all_gts, \n#             os.path.dirname(output_path), os.path.basename(output_path),\n#             confusionMat=True,\n#             prodAccuracy=True,\n#             averageAccuracy=True,\n#             kappaCoeff=True,\n#             title=title\n#         )\n        \n#         # Save prediction images\n#         for pred, tile_id in zip(all_preds, valid_test_ids):\n#             img = convert_to_color(pred)\n#             save_path = f\"{output_path}/segmentation_result_area{tile_id}.png\"\n#             io.imsave(save_path, img)\n#             print(f\"Saved prediction to {save_path}\")\n    \n#     return acc, all_preds, all_gts","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 9: Training (Optional)\n# Set TRAIN_MODEL to True to train, False to skip training\nTRAIN_MODEL = True  # Change to True to train the model\n\nif TRAIN_MODEL:\n    print(\"Starting model training...\")\n    model_path = train_model(\n        net=net,\n        optimizer=optimizer,\n        scheduler=scheduler,\n        train_loader=train_loader,\n        epochs=EPOCHS,\n        save_epoch=SAVE_EPOCH,\n        weights=WEIGHTS,\n        output_path=f\"{OUTPUT_ROOT}/{EXPERIMENT_NAME}\"\n    )\n    print(f\"Training completed! Model saved to {model_path}\")\nelse:\n    print(\"Skipping model training.\")\n    # Specify a pre-trained model path here if needed\n    # model_path = 'path/to/pretrained/model.pth'\n    # net.load_state_dict(torch.load(model_path))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 10: Testing\n# Set TEST_MODEL to True to test the model\nTEST_MODEL = True\n\nif TEST_MODEL:\n    print(\"Starting model testing...\")\n    \n    # Test the model\n    accuracy, all_preds, all_gts = test_model(\n        net=net,\n        test_ids=test_ids,\n        data_files=DATA_FILES,\n        label_files=LABEL_FILES,\n        eroded_files=ERODED_FILES,\n        labels=LABELS,\n        stride=STRIDE,\n        batch_size=BATCH_SIZE,\n        window_size=WINDOW_SIZE,\n        output_path=f\"{OUTPUT_ROOT}/{EXPERIMENT_NAME}\"\n    )\n    \n    print(f\"Testing completed with overall accuracy: {accuracy:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 11: Visualization\nif TEST_MODEL and 'all_preds' in locals():\n    print(\"Generating visualization of results...\")\n    \n    # Create a visualization of all test results\n    n_images = len(test_ids)\n    fig, axes = plt.subplots(n_images, 3, figsize=(15, 5*n_images))\n    \n    for i, (id, pred, gt) in enumerate(zip(test_ids, all_preds, all_gts)):\n        # Load original image\n        img = 1/255 * np.asarray(io.imread(DATA_FILES.format(id)), dtype='float32')\n        \n        # Display original image, ground truth, and prediction\n        if n_images > 1:\n            axes[i, 0].imshow(np.asarray(255 * img, dtype='uint8'))\n            axes[i, 0].set_title(f'Area {id} - Original')\n            axes[i, 1].imshow(convert_to_color(gt))\n            axes[i, 1].set_title('Ground Truth')\n            axes[i, 2].imshow(convert_to_color(pred))\n            axes[i, 2].set_title('Prediction')\n        else:\n            axes[0].imshow(np.asarray(255 * img, dtype='uint8'))\n            axes[0].set_title(f'Area {id} - Original')\n            axes[1].imshow(convert_to_color(gt))\n            axes[1].set_title('Ground Truth')\n            axes[2].imshow(convert_to_color(pred))\n            axes[2].set_title('Prediction')\n    \n    plt.tight_layout()\n    plt.savefig(f\"{OUTPUT_ROOT}/{EXPERIMENT_NAME}/all_results.png\", dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    print(f\"Results visualization saved to {OUTPUT_ROOT}/{EXPERIMENT_NAME}/all_results.png\")\n\nprint(\"Pipeline completed successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}