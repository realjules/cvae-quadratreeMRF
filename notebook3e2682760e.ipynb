{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":323641,"sourceType":"datasetVersion","datasetId":136436},{"sourceId":277914,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":238030,"modelId":259698},{"sourceId":277925,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":238040,"modelId":259708}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NEW CODE","metadata":{}},{"cell_type":"code","source":"# CRFNet-RS: Semantic Segmentation for Remote Sensing Images\n\n# Cell 1: Setup Environment\nimport os\nimport sys\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport random\nfrom tqdm.notebook import tqdm\nfrom glob import glob\nimport time\nfrom datetime import datetime\n\n# Set random seeds for reproducibility\nrandom.seed(42)\ntorch.manual_seed(42)\nnp.random.seed(42)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(42)\n\n# Clone the repository\n!git clone https://github.com/Ayana-Inria/CRFNet-RS.git\nsys.path.append('./CRFNet-RS')\n\n# Install dependencies\n!pip install -r ./CRFNet-RS/requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:24:25.402439Z","iopub.execute_input":"2025-03-21T16:24:25.402678Z","iopub.status.idle":"2025-03-21T16:24:37.123695Z","shell.execute_reply.started":"2025-03-21T16:24:25.402658Z","shell.execute_reply":"2025-03-21T16:24:37.122527Z"}},"outputs":[{"name":"stdout","text":"fatal: destination path 'CRFNet-RS' already exists and is not an empty directory.\nCollecting matplotlib==3.7.0 (from -r ./CRFNet-RS/requirements.txt (line 1))\n  Downloading matplotlib-3.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\nCollecting numpy==1.21.0 (from -r ./CRFNet-RS/requirements.txt (line 2))\n  Downloading numpy-1.21.0.zip (10.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nCollecting opencv-python==4.7.0.68 (from -r ./CRFNet-RS/requirements.txt (line 3))\n  Downloading opencv_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.10.0+cu111 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.10.0+cu111\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Cell 2: Fix Imports in main.py\n# Fix the unet import issue\nwith open('./CRFNet-RS/main.py', 'r') as file:\n    content = file.read()\n\n# Replace the incorrect import\nfixed_content = content.replace('from net.unet import *', '# from net.unet import *')\n\nwith open('./CRFNet-RS/main.py', 'w') as file:\n    file.write(fixed_content)\n\nprint(\"Fixed import in main.py\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:24:37.125693Z","iopub.execute_input":"2025-03-21T16:24:37.126015Z","iopub.status.idle":"2025-03-21T16:24:37.132039Z","shell.execute_reply.started":"2025-03-21T16:24:37.125961Z","shell.execute_reply":"2025-03-21T16:24:37.131309Z"}},"outputs":[{"name":"stdout","text":"Fixed import in main.py\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Cell 3: Configure Paths and Parameters\n# Configuration parameters\nWINDOW_SIZE = (256, 256)  # Patch size\nSTRIDE = 32  # Stride for testing inference\nIN_CHANNELS = 3  # Number of input channels (RGB/IRRG)\nBATCH_SIZE = 10  # Mini-batch size\nEPOCHS = 30  # Number of training epochs\nSAVE_EPOCH = 10  # Save model every N epochs\nBASE_LR = 0.01  # Base learning rate\nWEIGHT_DECAY = 0.0005  # Weight decay for optimizer\n\n# Dataset parameters\nDATASET_TYPE = \"Vaihingen\"  # Options: \"Vaihingen\" or \"Potsdam\"\nGT_TYPE = \"conncomp\"  # Options: \"full\", \"conncomp\", \"ero\"\nERO_DISK_SIZE = 8  # Size of erosion disk for ground truth processing\n\n# Organize folders\nDATA_ROOT = \"/kaggle/input/potsdamvaihingen/\"  # Change to your data path\nOUTPUT_ROOT = \"/kaggle/working/\"\nEXPERIMENT_NAME = f\"CRFNet_{DATASET_TYPE}_{GT_TYPE}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n\n# Create output directory\nos.makedirs(DATA_ROOT, exist_ok=True)\nos.makedirs(f\"{DATA_ROOT}/top\", exist_ok=True)\nos.makedirs(f\"{DATA_ROOT}/gt\", exist_ok=True)\nos.makedirs(f\"{DATA_ROOT}/gt_eroded\", exist_ok=True)\nos.makedirs(OUTPUT_ROOT, exist_ok=True)\nos.makedirs(f\"{OUTPUT_ROOT}/{EXPERIMENT_NAME}\", exist_ok=True)\n\n# Set paths based on dataset\nif DATASET_TYPE == \"Vaihingen\":\n    train_ids = ['1', '3', '23', '26', '7', '11', '13', '28', '17', '32', '34', '37']\n    test_ids = ['5', '15', '21', '30']\nelse:  # Potsdam\n    train_ids = ['3_11', '4_11', '5_10', '6_7', '6_8', '6_9', '7_7', '7_8', '7_9', '7_10']\n    test_ids = ['3_12', '4_10', '4_12', '5_11', '6_12']\n\n# Data file paths\nDATA_FILES = f\"{DATA_ROOT}/ISPRS_semantic_labeling_Vaihingen/top/top_mosaic_09cm_area{}.tif\"\nLABEL_FILES = f\"{DATA_ROOT}/ISPRS_semantic_labeling_Vaihingen/gts_for_participants/top_mosaic_09cm_area{}.tif\"\nERODED_FILES = f\"{DATA_ROOT}/5_Labels_for_participants_no_Boundary/5_Labels_for_participants_no_Boundary/top_potsdam_{}_{}_label_noBoundary.tif\"\n\n# Class labels\nLABELS = [\"roads\", \"buildings\", \"low veg.\", \"trees\", \"cars\", \"clutter\"]\nN_CLASSES = len(LABELS)\n\n\n# Update these lines in your main script\n# DATA_FOLDER = FOLDER + '/ISPRS_semantic_labeling_Vaihingen/top/top_mosaic_09cm_area{}.tif'\n# LABEL_FOLDER = FOLDER + '/ISPRS_semantic_labeling_Vaihingen/gts_for_participants/top_mosaic_09cm_area{}.tif'\n# ERODED_FOLDER = FOLDER + '/5_Labels_for_participants_no_Boundary/5_Labels_for_participants_no_Boundary/top_potsdam_{}_{}_label_noBoundary.tif'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:35:01.483729Z","iopub.execute_input":"2025-03-21T16:35:01.484075Z","iopub.status.idle":"2025-03-21T16:35:01.491636Z","shell.execute_reply.started":"2025-03-21T16:35:01.484046Z","shell.execute_reply":"2025-03-21T16:35:01.490435Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-a953e84c42cc>\"\u001b[0;36m, line \u001b[0;32m39\u001b[0m\n\u001b[0;31m    DATA_FILES = f\"{DATA_ROOT}/ISPRS_semantic_labeling_Vaihingen/top/top_mosaic_09cm_area{}.tif\"\u001b[0m\n\u001b[0m                                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: empty expression not allowed\n"],"ename":"SyntaxError","evalue":"f-string: empty expression not allowed (<ipython-input-10-a953e84c42cc>, line 39)","output_type":"error"}],"execution_count":10},{"cell_type":"code","source":"# Cell 3: Configure Paths and Parameters\nimport os\nfrom datetime import datetime\n\n# Configuration parameters\nWINDOW_SIZE = (256, 256)  # Patch size\nSTRIDE = 32  # Stride for testing inference\nIN_CHANNELS = 3  # Number of input channels (RGB/IRRG)\nBATCH_SIZE = 10  # Mini-batch size\nEPOCHS = 30  # Number of training epochs\nSAVE_EPOCH = 10  # Save model every N epochs\nBASE_LR = 0.01  # Base learning rate\nWEIGHT_DECAY = 0.0005  # Weight decay for optimizer\n\n# Dataset parameters\nDATASET_TYPE = \"Vaihingen\"  # Options: \"Vaihingen\" or \"Potsdam\"\nGT_TYPE = \"conncomp\"  # Options: \"full\", \"conncomp\", \"ero\"\nERO_DISK_SIZE = 8  # Size of erosion disk for ground truth processing\n\n# Organize folders\nDATA_ROOT = \"/kaggle/input/potsdamvaihingen/\"  # Change to your data path\nOUTPUT_ROOT = \"/kaggle/working/\"\nEXPERIMENT_NAME = f\"CRFNet_{DATASET_TYPE}_{GT_TYPE}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n\n# Create output directory\nos.makedirs(DATA_ROOT, exist_ok=True)\nos.makedirs(f\"{DATA_ROOT}/top\", exist_ok=True)\nos.makedirs(f\"{DATA_ROOT}/gt\", exist_ok=True)\nos.makedirs(f\"{DATA_ROOT}/gt_eroded\", exist_ok=True)\nos.makedirs(OUTPUT_ROOT, exist_ok=True)\nos.makedirs(f\"{OUTPUT_ROOT}/{EXPERIMENT_NAME}\", exist_ok=True)\n\n# Set paths based on dataset\nif DATASET_TYPE == \"Vaihingen\":\n    train_ids = ['1', '3', '23', '26', '7', '11', '13', '28', '17', '32', '34', '37']\n    test_ids = ['5', '15', '21', '30']\nelse:  # Potsdam\n    train_ids = ['3_11', '4_11', '5_10', '6_7', '6_8', '6_9', '7_7', '7_8', '7_9', '7_10']\n    test_ids = ['3_12', '4_10', '4_12', '5_11', '6_12']\n\n# Data file paths - removed the empty {} and made them templates to be formatted later\nDATA_FILES = f\"{DATA_ROOT}/ISPRS_semantic_labeling_Vaihingen/top/top_mosaic_09cm_area\"\nLABEL_FILES = f\"{DATA_ROOT}/ISPRS_semantic_labeling_Vaihingen/gts_for_participants/top_mosaic_09cm_area\"\nERODED_FILES = f\"{DATA_ROOT}/5_Labels_for_participants_no_Boundary/5_Labels_for_participants_no_Boundary/top_potsdam\"\n\n# Class labels\nLABELS = [\"roads\", \"buildings\", \"low veg.\", \"trees\", \"cars\", \"clutter\"]\nN_CLASSES = len(LABELS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:37:38.772119Z","iopub.execute_input":"2025-03-21T16:37:38.772453Z","iopub.status.idle":"2025-03-21T16:37:38.820018Z","shell.execute_reply.started":"2025-03-21T16:37:38.772430Z","shell.execute_reply":"2025-03-21T16:37:38.818985Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-aca33680bb09>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Create output directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_ROOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{DATA_ROOT}/top\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{DATA_ROOT}/gt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{DATA_ROOT}/gt_eroded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/kaggle/input/potsdamvaihingen//top'"],"ename":"OSError","evalue":"[Errno 30] Read-only file system: '/kaggle/input/potsdamvaihingen//top'","output_type":"error"}],"execution_count":11},{"cell_type":"code","source":"# Open the file and fix the indentation\n!cat /kaggle/working/CRFNet-RS/utils/utils_network.py | head -90\n!sed -i '89s/^/        /' /kaggle/working/CRFNet-RS/utils/utils_network.py\nfrom net.net import CRFNet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:24:37.155533Z","iopub.status.idle":"2025-03-21T16:24:37.155792Z","shell.execute_reply":"2025-03-21T16:24:37.155691Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 4: Import Required Modules\nfrom dataset.dataset import ISPRS_dataset\nfrom utils.utils_dataset import convert_from_color, convert_to_color, disk\nfrom utils.utils import metrics, sliding_window, count_sliding_window, grouper\nfrom utils.export_result import set_output_location, export_results\nfrom net.net import CRFNet\nfrom net.loss import CrossEntropy2d\nfrom skimage import io\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\n# Display dataset information\nprint(f\"Dataset: {DATASET_TYPE}\")\nprint(f\"Ground Truth Type: {GT_TYPE}\")\nprint(f\"Training on {len(train_ids)} tiles: {train_ids}\")\nprint(f\"Testing on {len(test_ids)} tiles: {test_ids}\")\nprint(f\"Using {'GPU' if torch.cuda.is_available() else 'CPU'} for computation\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:24:37.156367Z","iopub.status.idle":"2025-03-21T16:24:37.156744Z","shell.execute_reply":"2025-03-21T16:24:37.156591Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 5: Initialize Model and Optimizer\n# Initialize the CRFNet model\nnet = CRFNet(n_channels=IN_CHANNELS, n_classes=N_CLASSES, bilinear=True)\n\n# Setup optimizer and learning rate scheduler\noptimizer = optim.SGD(net.parameters(), lr=BASE_LR, momentum=0.9, weight_decay=WEIGHT_DECAY)\nscheduler = optim.lr_scheduler.MultiStepLR(optimizer, [25, 35, 45], gamma=0.1)\n\n# Move model to GPU if available\nif torch.cuda.is_available():\n    net.cuda()\n    WEIGHTS = torch.ones(N_CLASSES).cuda()\nelse:\n    WEIGHTS = torch.ones(N_CLASSES)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:24:37.157682Z","iopub.status.idle":"2025-03-21T16:24:37.158056Z","shell.execute_reply":"2025-03-21T16:24:37.157883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 6: Define Training Function\ndef train_model(net, optimizer, scheduler, train_loader, epochs, save_epoch, weights, output_path):\n    \"\"\"\n    Train the CRFNet model\n    \"\"\"\n    # Import any missing modules needed for training\n    import torch.nn.functional as F\n    import cv2\n    from utils.utils_network import compute_class_weight\n    from net.train import train\n    \n    # Run the training function\n    train(net, optimizer, epochs, save_epoch, weights, train_loader, BATCH_SIZE, WINDOW_SIZE, output_path, scheduler)\n    \n    # Save final model\n    final_model_path = f'{output_path}/model_final.pth'\n    return final_model_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:24:37.158692Z","iopub.status.idle":"2025-03-21T16:24:37.159078Z","shell.execute_reply":"2025-03-21T16:24:37.158881Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 7: Define Testing Function\ndef test_model(net, test_ids, data_files, label_files, eroded_files, labels, stride, batch_size, window_size, output_path=None):\n    \"\"\"\n    Test the model on the provided test data\n    \"\"\"\n    from net.test_network import test\n    \n    # Load test data\n    test_images = [1/255 * np.asarray(io.imread(data_files.format(id)), dtype='float32') for id in test_ids]\n    test_labels = [np.asarray(io.imread(label_files.format(id)), dtype='uint8') for id in test_ids]\n    eroded_labels = [convert_from_color(io.imread(eroded_files.format(id))) for id in test_ids]\n    \n    # Run the test\n    acc, all_preds, all_gts = test(\n        net, test_ids, test_images, test_labels, eroded_labels, \n        labels, stride, batch_size, window_size=window_size, all=True\n    )\n    \n    # Export results\n    if output_path:\n        title = \"Quantitative results for CRFNet testing\"\n        export_results(\n            all_preds, all_gts, \n            os.path.dirname(output_path), os.path.basename(output_path),\n            confusionMat=True,\n            prodAccuracy=True,\n            averageAccuracy=True,\n            kappaCoeff=True,\n            title=title\n        )\n        \n        # Save prediction images\n        for pred, tile_id in zip(all_preds, test_ids):\n            img = convert_to_color(pred)\n            io.imsave(f\"{output_path}/segmentation_result_area{tile_id}.png\", img)\n    \n    return acc, all_preds, all_gts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:24:37.159855Z","iopub.status.idle":"2025-03-21T16:24:37.160234Z","shell.execute_reply":"2025-03-21T16:24:37.160077Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 8: Create Datasets\n# Initialize training dataset\ntrain_set = ISPRS_dataset(\n    ids=train_ids,\n    ids_type='TRAIN',\n    gt_type=GT_TYPE,\n    gt_modification=disk(ERO_DISK_SIZE),\n    data_files=DATA_FILES,\n    label_files=LABEL_FILES,\n    window_size=WINDOW_SIZE,\n    cache=True,\n    augmentation=True\n)\n\n# Create data loader\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE)\nprint(f\"Created training loader with approximately {len(train_set) // BATCH_SIZE} batches per epoch\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:24:37.161220Z","iopub.status.idle":"2025-03-21T16:24:37.161581Z","shell.execute_reply":"2025-03-21T16:24:37.161423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test_model(net, test_ids, data_files, label_files, eroded_files, labels, stride, batch_size, window_size, output_path=None):\n    \"\"\"\n    Test the model on the provided test data\n    \"\"\"\n    from net.test_network import test\n    from skimage import io\n    import numpy as np\n    import os\n    from utils.utils_dataset import convert_from_color\n    from utils.export_result import export_results\n    \n    all_preds = []\n    all_gts = []\n    \n    # Load test data safely with error handling\n    test_images = []\n    test_labels = []\n    eroded_labels = []\n    \n    for id in test_ids:\n        print(f\"Loading test data for tile {id}...\")\n        \n        # Load input image\n        try:\n            img = 1/255 * np.asarray(io.imread(data_files.format(id)), dtype='float32')\n            test_images.append(img)\n            print(f\"Image shape: {img.shape}\")\n        except Exception as e:\n            print(f\"Error loading image for tile {id}: {e}\")\n            continue\n        \n        # Load label\n        try:\n            label = np.asarray(io.imread(label_files.format(id)), dtype='uint8')\n            test_labels.append(label)\n            print(f\"Label shape: {label.shape}\")\n        except Exception as e:\n            print(f\"Error loading label for tile {id}: {e}\")\n            # Remove the corresponding image\n            test_images.pop()\n            continue\n        \n        # Load eroded label\n        try:\n            eroded = io.imread(eroded_files.format(id))\n            print(f\"Eroded label initial shape: {eroded.shape}\")\n            \n            # Check if the image is already a 2D array (grayscale)\n            if len(eroded.shape) == 2:\n                # This is already a label map, no need to convert from color\n                eroded_label = eroded\n            else:\n                # This is an RGB image, convert from color\n                eroded_label = convert_from_color(eroded)\n                \n            eroded_labels.append(eroded_label)\n            print(f\"Processed eroded label shape: {eroded_label.shape}\")\n        except Exception as e:\n            print(f\"Error loading eroded label for tile {id}: {e}\")\n            # Remove the corresponding image and label\n            test_images.pop()\n            test_labels.pop()\n            continue\n    \n    # Make sure we have data to test\n    if not test_images:\n        print(\"No valid test data found. Check your file paths and image formats.\")\n        return 0, [], []\n    \n    # Update test_ids to only include those we successfully loaded\n    valid_test_ids = test_ids[:len(test_images)]\n    print(f\"Testing on {len(valid_test_ids)} valid tiles: {valid_test_ids}\")\n    \n    # Run the test\n    acc, all_preds, all_gts = test(\n        net, valid_test_ids, test_images, test_labels, eroded_labels, \n        labels, stride, batch_size, window_size=window_size, all=True\n    )\n    \n    # Export results\n    if output_path and all_preds:\n        title = \"Quantitative results for CRFNet testing\"\n        export_results(\n            all_preds, all_gts, \n            os.path.dirname(output_path), os.path.basename(output_path),\n            confusionMat=True,\n            prodAccuracy=True,\n            averageAccuracy=True,\n            kappaCoeff=True,\n            title=title\n        )\n        \n        # Save prediction images\n        for pred, tile_id in zip(all_preds, valid_test_ids):\n            img = convert_to_color(pred)\n            save_path = f\"{output_path}/segmentation_result_area{tile_id}.png\"\n            io.imsave(save_path, img)\n            print(f\"Saved prediction to {save_path}\")\n    \n    return acc, all_preds, all_gts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:24:37.162320Z","iopub.status.idle":"2025-03-21T16:24:37.162689Z","shell.execute_reply":"2025-03-21T16:24:37.162529Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 9: Training (Optional)\n# Set TRAIN_MODEL to True to train, False to skip training\nTRAIN_MODEL = True  # Change to True to train the model\n\nif TRAIN_MODEL:\n    print(\"Starting model training...\")\n    model_path = train_model(\n        net=net,\n        optimizer=optimizer,\n        scheduler=scheduler,\n        train_loader=train_loader,\n        epochs=EPOCHS,\n        save_epoch=SAVE_EPOCH,\n        weights=WEIGHTS,\n        output_path=f\"{OUTPUT_ROOT}/{EXPERIMENT_NAME}\"\n    )\n    print(f\"Training completed! Model saved to {model_path}\")\nelse:\n    print(\"Skipping model training.\")\n    # Specify a pre-trained model path here if needed\n    # model_path = 'path/to/pretrained/model.pth'\n    # net.load_state_dict(torch.load(model_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:24:37.163589Z","iopub.status.idle":"2025-03-21T16:24:37.163938Z","shell.execute_reply":"2025-03-21T16:24:37.163786Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 10: Testing\n# Set TEST_MODEL to True to test the model\nTEST_MODEL = True\n\nif TEST_MODEL:\n    print(\"Starting model testing...\")\n    \n    # Test the model\n    accuracy, all_preds, all_gts = test_model(\n        net=net,\n        test_ids=test_ids,\n        data_files=DATA_FILES,\n        label_files=LABEL_FILES,\n        eroded_files=ERODED_FILES,\n        labels=LABELS,\n        stride=STRIDE,\n        batch_size=BATCH_SIZE,\n        window_size=WINDOW_SIZE,\n        output_path=f\"{OUTPUT_ROOT}/{EXPERIMENT_NAME}\"\n    )\n    \n    print(f\"Testing completed with overall accuracy: {accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:24:37.164663Z","iopub.status.idle":"2025-03-21T16:24:37.165037Z","shell.execute_reply":"2025-03-21T16:24:37.164861Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 11: Visualization\nif TEST_MODEL and 'all_preds' in locals():\n    print(\"Generating visualization of results...\")\n    \n    # Create a visualization of all test results\n    n_images = len(test_ids)\n    fig, axes = plt.subplots(n_images, 3, figsize=(15, 5*n_images))\n    \n    for i, (id, pred, gt) in enumerate(zip(test_ids, all_preds, all_gts)):\n        # Load original image\n        img = 1/255 * np.asarray(io.imread(DATA_FILES.format(id)), dtype='float32')\n        \n        # Display original image, ground truth, and prediction\n        if n_images > 1:\n            axes[i, 0].imshow(np.asarray(255 * img, dtype='uint8'))\n            axes[i, 0].set_title(f'Area {id} - Original')\n            axes[i, 1].imshow(convert_to_color(gt))\n            axes[i, 1].set_title('Ground Truth')\n            axes[i, 2].imshow(convert_to_color(pred))\n            axes[i, 2].set_title('Prediction')\n        else:\n            axes[0].imshow(np.asarray(255 * img, dtype='uint8'))\n            axes[0].set_title(f'Area {id} - Original')\n            axes[1].imshow(convert_to_color(gt))\n            axes[1].set_title('Ground Truth')\n            axes[2].imshow(convert_to_color(pred))\n            axes[2].set_title('Prediction')\n    \n    plt.tight_layout()\n    plt.savefig(f\"{OUTPUT_ROOT}/{EXPERIMENT_NAME}/all_results.png\", dpi=300, bbox_inches='tight')\n    plt.show()\n    \n    print(f\"Results visualization saved to {OUTPUT_ROOT}/{EXPERIMENT_NAME}/all_results.png\")\n\nprint(\"Pipeline completed successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T16:24:37.165989Z","iopub.status.idle":"2025-03-21T16:24:37.166345Z","shell.execute_reply":"2025-03-21T16:24:37.166191Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}