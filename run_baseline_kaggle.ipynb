{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!rm -rf cvae-quadratreeMRF # Remove old version if exists\n",
    "!git clone https://github.com/realjules/cvae-quadratreeMRF.git\n",
    "import sys\n",
    "sys.path.append('/kaggle/working/cvae-quadratreeMRF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage.morphology import disk\n",
    "from glob import glob\n",
    "import random\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import project modules\n",
    "from dataset.dataset import ISPRS_dataset\n",
    "from net.net import CRFNet\n",
    "from net.loss import CrossEntropy2d\n",
    "from utils.utils_dataset import convert_to_color, convert_from_color\n",
    "from utils.utils_network import compute_class_weight\n",
    "from utils.utils import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Configure parameters\n",
    "# Dataset parameters\n",
    "WINDOW_SIZE = (256, 256)  # Patch size\n",
    "STRIDE = 32  # Stride for testing\n",
    "IN_CHANNELS = 3  # Number of input channels (RGB)\n",
    "FOLDER = \"../input/potsdamvaihingen/\"  # Dataset path\n",
    "BATCH_SIZE = 10  # Mini-batch size\n",
    "\n",
    "# Training parameters\n",
    "EPOCHS = 30  # Training epochs\n",
    "SAVE_EPOCH = 10  # Save model interval\n",
    "OUTPUT_FOLDER = \"./output\"  # Output directory\n",
    "ERO_DISK_SIZE = 3  # Erosion disk size\n",
    "BASE_LR = 0.01  # Base learning rate\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "# Labels and classes\n",
    "LABELS = [\"roads\", \"buildings\", \"low veg.\", \"trees\", \"cars\", \"clutter\"]\n",
    "N_CLASSES = len(LABELS)\n",
    "WEIGHTS = torch.ones(N_CLASSES)\n",
    "CACHE = True  # Store dataset in-memory\n",
    "\n",
    "# Data paths\n",
    "MAIN_FOLDER = FOLDER + 'ISPRS_semantic_labeling_Vaihingen/'\n",
    "DATA_FOLDER = MAIN_FOLDER + 'top/top_mosaic_09cm_area{}.tif'\n",
    "LABEL_FOLDER = MAIN_FOLDER + 'gts_for_participants/top_mosaic_09cm_area{}.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define train/test split\n",
    "train_ids = ['1', '3', '23', '26', '7', '11', '13', '28', '17', '32', '34', '37']\n",
    "test_ids = ['5', '21', '15', '30'] \n",
    "print(f\"Training on {len(train_ids)} tiles: {train_ids}\")\n",
    "print(f\"Testing on {len(test_ids)} tiles: {test_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the ISPRS color palette\n",
    "# ISPRS color palette\n",
    "palette = {\n",
    "    0: (255, 255, 255),  # Impervious surfaces (white)\n",
    "    1: (0, 0, 255),      # Buildings (blue)\n",
    "    2: (0, 255, 255),    # Low vegetation (cyan)\n",
    "    3: (0, 255, 0),      # Trees (green)\n",
    "    4: (255, 255, 0),    # Cars (yellow)\n",
    "    5: (255, 0, 0),      # Clutter (red)\n",
    "    6: (0, 0, 0)         # Undefined (black)\n",
    "}\n",
    "\n",
    "invert_palette = {v: k for k, v in palette.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualize a sample image and its ground truth\n",
    "try:\n",
    "    # Load a sample image\n",
    "    img = io.imread(DATA_FOLDER.format(train_ids[0]))\n",
    "    \n",
    "    # Load ground truth\n",
    "    gt = io.imread(LABEL_FOLDER.format(train_ids[0]))\n",
    "    \n",
    "    # Display\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Sample Image (Area {})'.format(train_ids[0]))\n",
    "    ax2.imshow(gt)\n",
    "    ax2.set_title('Ground Truth')\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading sample data: {e}\")\n",
    "    print(\"Continuing with training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize datasets\n",
    "print(\"Initializing datasets...\")\n",
    "train_set = ISPRS_dataset(\n",
    "    ids=train_ids,\n",
    "    ids_type='TRAIN',\n",
    "    gt_type='full',  # 'full', 'conncomp', or 'ero'\n",
    "    gt_modification=disk(ERO_DISK_SIZE),\n",
    "    data_files=DATA_FOLDER,\n",
    "    label_files=LABEL_FOLDER,\n",
    "    window_size=WINDOW_SIZE,\n",
    "    cache=CACHE,\n",
    "    augmentation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE)\n",
    "print(f\"Created data loader with {len(train_loader)} batches per epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "print(\"Initializing model...\")\n",
    "net = CRFNet(n_channels=IN_CHANNELS, n_classes=N_CLASSES, bilinear=True)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net.to(device)\n",
    "if torch.cuda.is_available():\n",
    "    WEIGHTS = WEIGHTS.cuda()\n",
    "print(f\"Model will train on: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize optimizer and scheduler\n",
    "optimizer = optim.SGD(net.parameters(), lr=BASE_LR, momentum=0.9, weight_decay=0.0005)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [25, 35, 45], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model():\n",
    "    # More efficient storage size for losses\n",
    "    max_iterations = EPOCHS * len(train_loader)\n",
    "    losses = np.zeros(max_iterations)\n",
    "    mean_losses = np.zeros(max_iterations)\n",
    "    \n",
    "    iter_ = 0\n",
    "    \n",
    "    for e in tqdm(range(1, EPOCHS + 1), desc=\"Epochs\"):\n",
    "        net.train()\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(tqdm(train_loader, desc=f\"Epoch {e}\", leave=False)):\n",
    "            # Process targets for multi-scale supervision\n",
    "            target_np = target.data.cpu().numpy()\n",
    "            target_np = np.transpose(target_np, [1, 2, 0])\n",
    "            \n",
    "            # Create multi-scale targets\n",
    "            scales = [(32, 32), (64, 64), (128, 128)]\n",
    "            targets_resized = []\n",
    "            \n",
    "            for size in scales:\n",
    "                targets_resized.append(\n",
    "                    np.transpose(\n",
    "                        cv2.resize(target_np, dsize=size, interpolation=cv2.INTER_NEAREST), \n",
    "                        [2, 0, 1]\n",
    "                    )\n",
    "                )\n",
    "            \n",
    "            # Original target back to channel-first\n",
    "            target_np = np.transpose(target_np, [2, 0, 1])\n",
    "            \n",
    "            # Move data to device\n",
    "            data = data.to(device)\n",
    "            target_tensor = torch.from_numpy(target_np).to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            output, out_fc, out_neigh, _ = net(data)\n",
    "            \n",
    "            # Calculate main loss\n",
    "            loss = CrossEntropy2d(output, target_tensor, weight=WEIGHTS)\n",
    "            \n",
    "            # Multi-scale losses\n",
    "            fc_losses = []\n",
    "            for i, t in enumerate(targets_resized):\n",
    "                t_tensor = torch.from_numpy(t).type(torch.LongTensor).to(device)\n",
    "                weights = compute_class_weight(t).to(device)\n",
    "                fc_losses.append(CrossEntropy2d(out_fc[i], t_tensor, weight=weights))\n",
    "            \n",
    "            # Pairwise loss for neighborhood consistency\n",
    "            pairwise_loss = CrossEntropy2d(out_neigh, target_tensor, weight=WEIGHTS)\n",
    "            \n",
    "            # Combine losses\n",
    "            total_loss = (loss + sum(fc_losses)) / (1 + len(fc_losses)) + pairwise_loss\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Record loss\n",
    "            losses[iter_] = total_loss.item()\n",
    "            mean_losses[iter_] = np.mean(losses[max(0, iter_-100):iter_+1])\n",
    "            \n",
    "            # Display progress every 100 iterations\n",
    "            if iter_ % 100 == 0:\n",
    "                # Visualize results\n",
    "                with torch.no_grad():\n",
    "                    # Convert to CPU for visualization\n",
    "                    rgb = np.asarray(255 * np.transpose(data.cpu().numpy()[0], (1, 2, 0)), dtype='uint8')\n",
    "                    pred = np.argmax(output.cpu().numpy()[0], axis=0)\n",
    "                    gt = target_tensor.cpu().numpy()[0]\n",
    "                    \n",
    "                    # Print progress\n",
    "                    acc = accuracy(pred, gt)\n",
    "                    print(f'Epoch {e}/{EPOCHS} [{batch_idx}/{len(train_loader)} ({100*batch_idx/len(train_loader):.0f}%)] Loss: {total_loss.item():.4f} Acc: {acc:.2f}%')\n",
    "                    \n",
    "                    # Plot loss curve\n",
    "                    plt.figure(figsize=(10, 4))\n",
    "                    plt.plot(mean_losses[:iter_+1])\n",
    "                    plt.title('Mean Loss')\n",
    "                    plt.grid(True)\n",
    "                    plt.xlabel('Iterations')\n",
    "                    plt.ylabel('Loss')\n",
    "                    plt.show()\n",
    "                    \n",
    "                    # Visualize predictions\n",
    "                    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                    ax1.imshow(rgb)\n",
    "                    ax1.set_title('RGB Input')\n",
    "                    ax2.imshow(convert_to_color(gt))\n",
    "                    ax2.set_title('Ground Truth')\n",
    "                    ax3.imshow(convert_to_color(pred))\n",
    "                    ax3.set_title('Prediction')\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "            \n",
    "            iter_ += 1\n",
    "            \n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save model checkpoint\n",
    "        if e % SAVE_EPOCH == 0:\n",
    "            torch.save(net.state_dict(), f'{OUTPUT_FOLDER}/model_epoch{e}.pth')\n",
    "    \n",
    "    # Save final model\n",
    "    torch.save(net.state_dict(), f'{OUTPUT_FOLDER}/model_final.pth')\n",
    "    print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Run the training\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define testing function\n",
    "from net.test_network import test\n",
    "\n",
    "def evaluate_model(model_path):\n",
    "    \"\"\"Evaluate the trained model on the test set\"\"\"\n",
    "    print(f\"Loading model from {model_path}\")\n",
    "    net.load_state_dict(torch.load(model_path))\n",
    "    net.eval()\n",
    "    \n",
    "    print(\"Preparing test data...\")\n",
    "    # Load test images and labels\n",
    "    test_images = [1/255 * np.asarray(io.imread(DATA_FOLDER.format(id)), dtype='float32') for id in test_ids]\n",
    "    test_labels = [np.asarray(io.imread(LABEL_FOLDER.format(id)), dtype='uint8') for id in test_ids]\n",
    "    \n",
    "    print(\"Running evaluation...\")\n",
    "    # Evaluate the model\n",
    "    all_preds = []\n",
    "    all_gts = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (img, gt) in enumerate(zip(test_images, test_labels)):\n",
    "            print(f\"Processing test image {i+1}/{len(test_images)} (Area {test_ids[i]})\")\n",
    "            \n",
    "            # Process the ground truth\n",
    "            gt_processed = convert_from_color(gt)\n",
    "            all_gts.append(gt_processed)\n",
    "            \n",
    "            # Prepare the image tensor\n",
    "            img = np.transpose(img, (2, 0, 1))  # CHW format\n",
    "            \n",
    "            # Slide window over the image\n",
    "            pred = np.zeros(gt_processed.shape, dtype=int)\n",
    "            counts = np.zeros(gt_processed.shape, dtype=int)\n",
    "            \n",
    "            for x in range(0, img.shape[1] - WINDOW_SIZE[0] + 1, STRIDE):\n",
    "                for y in range(0, img.shape[2] - WINDOW_SIZE[1] + 1, STRIDE):\n",
    "                    # Extract patch\n",
    "                    patch = img[:, x:x+WINDOW_SIZE[0], y:y+WINDOW_SIZE[1]]\n",
    "                    patch_tensor = torch.from_numpy(patch).unsqueeze(0).to(device)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    outputs = net(patch_tensor)[0]\n",
    "                    \n",
    "                    # Get predictions\n",
    "                    patch_pred = np.argmax(outputs.cpu().numpy()[0], axis=0)\n",
    "                    \n",
    "                    # Update prediction and counts\n",
    "                    pred[x:x+WINDOW_SIZE[0], y:y+WINDOW_SIZE[1]] += patch_pred\n",
    "                    counts[x:x+WINDOW_SIZE[0], y:y+WINDOW_SIZE[1]] += 1\n",
    "            \n",
    "            # Average predictions\n",
    "            pred = np.divide(pred, counts, where=counts>0)\n",
    "            all_preds.append(pred)\n",
    "            \n",
    "            # Visualize results\n",
    "            fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "            ax1.imshow(np.transpose(img, (1, 2, 0)))\n",
    "            ax1.set_title(f'Test Image (Area {test_ids[i]})')\n",
    "            ax2.imshow(convert_to_color(gt_processed))\n",
    "            ax2.set_title('Ground Truth')\n",
    "            ax3.imshow(convert_to_color(pred))\n",
    "            ax3.set_title('Prediction')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    # Calculate metrics\n",
    "    from utils.utils import metrics\n",
    "    print(\"\\nComputing overall metrics...\")\n",
    "    metrics(\n",
    "        np.concatenate([p.flatten() for p in all_preds]),\n",
    "        np.concatenate([g.flatten() for g in all_gts]),\n",
    "        LABELS\n",
    "    )\n",
    "    \n",
    "    return all_preds, all_gts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Optionally run evaluation\n",
    "# Uncomment the lines below to evaluate the model after training\n",
    "# final_model_path = f'{OUTPUT_FOLDER}/model_final.pth'\n",
    "# all_preds, all_gts = evaluate_model(final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Export results (if needed)\n",
    "# from utils.export_result import export_results\n",
    "# \n",
    "# def save_results(predictions, ground_truths, exp_name=\"baseline\"):\n",
    "#     \"\"\"Save the prediction results\"\"\"\n",
    "#     export_results(\n",
    "#         predictions, \n",
    "#         ground_truths, \n",
    "#         OUTPUT_FOLDER, \n",
    "#         exp_name,\n",
    "#         confusionMat=True,\n",
    "#         prodAccuracy=True,\n",
    "#         averageAccuracy=True,\n",
    "#         kappaCoeff=True,\n",
    "#         title=f\"Results for {exp_name}\"\n",
    "#     )\n",
    "#     \n",
    "#     # Save visualization of predictions\n",
    "#     for pred, test_id in zip(predictions, test_ids):\n",
    "#         img = convert_to_color(pred)\n",
    "#         io.imsave(f'{OUTPUT_FOLDER}/{exp_name}_area{test_id}.png', img)\n",
    "#     \n",
    "#     print(f\"Results saved to {OUTPUT_FOLDER}\")\n",
    "# \n",
    "# # Uncomment to save results after evaluation\n",
    "# # save_results(all_preds, all_gts, \"baseline\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 136436,
     "sourceId": 323641,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}