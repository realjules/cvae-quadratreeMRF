{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":323641,"sourceType":"datasetVersion","datasetId":136436},{"sourceId":277914,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":238030,"modelId":259698},{"sourceId":277925,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":238040,"modelId":259708}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# NEW CODE","metadata":{}},{"cell_type":"code","source":"# CRFNet-RS: Semantic Segmentation for Remote Sensing Images with Multiple Sparsity Levels\n\n# Cell 1: Setup Environment\nimport os\nimport sys\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport random\nfrom tqdm.notebook import tqdm\nfrom glob import glob\nimport time\nfrom datetime import datetime\nfrom skimage import io\nfrom scipy import ndimage\n\n# Set random seeds for reproducibility\nrandom.seed(42)\ntorch.manual_seed(42)\nnp.random.seed(42)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(42)\n\n# Clone the repository\n!git clone https://github.com/Ayana-Inria/CRFNet-RS.git\nsys.path.append('./CRFNet-RS')\n\n# Install dependencies\n!pip install -r ./CRFNet-RS/requirements.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 2: Fix Issues in Repository\n# Fix the unet import issue\nwith open('./CRFNet-RS/main.py', 'r') as file:\n    content = file.read()\n\n# Replace the incorrect import\nfixed_content = content.replace('from net.unet import *', '# from net.unet import *')\n\nwith open('./CRFNet-RS/main.py', 'w') as file:\n    file.write(fixed_content)\n\n# Fix utils_network.py indentation\n!sed -i '89s/^/        /' /kaggle/working/CRFNet-RS/utils/utils_network.py\n\nprint(\"Fixed import in main.py and indentation in utils_network.py\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 3: Configure Paths and Parameters\n# Configuration parameters - these will be the same for all experiments\nWINDOW_SIZE = (256, 256)  # Patch size\nSTRIDE = 32  # Stride for testing inference\nIN_CHANNELS = 3  # Number of input channels (RGB/IRRG)\nBATCH_SIZE = 10  # Mini-batch size\nEPOCHS = 30  # Number of training epochs\nSAVE_EPOCH = 10  # Save model every N epochs\nBASE_LR = 0.01  # Base learning rate\nWEIGHT_DECAY = 0.0005  # Weight decay for optimizer\nDATASET_TYPE = \"Vaihingen\"  # Using Vaihingen dataset\n\n# Default parameters - can be overridden in run_experiment\nGT_TYPE = \"conncomp\"  # Options: \"full\", \"conncomp\", \"ero\"\nERO_DISK_SIZE = 8  # Size of erosion disk for ground truth processing\n\n# Organize folders\nDATA_ROOT = \"/kaggle/input/potsdamvaihingen/\"  # Input data path\nOUTPUT_ROOT = \"/kaggle/working/\"  # Working directory for outputs\nWORKING_DATA_ROOT = \"/kaggle/working/data\"  # Working directory for data processing\n\n# Create necessary directories\nos.makedirs(OUTPUT_ROOT, exist_ok=True)\nos.makedirs(WORKING_DATA_ROOT, exist_ok=True)\nos.makedirs(f\"{WORKING_DATA_ROOT}/top\", exist_ok=True)\nos.makedirs(f\"{WORKING_DATA_ROOT}/gt\", exist_ok=True)\nos.makedirs(f\"{WORKING_DATA_ROOT}/gt_eroded\", exist_ok=True)\n\n# Set paths based on dataset\ntrain_ids = ['1', '3', '23', '26', '7', '11', '13', '28', '17', '32', '34', '37']\ntest_ids = ['5', '15', '21', '30']\n\n# Data file paths\nDATA_FILES = f\"{DATA_ROOT}/ISPRS_semantic_labeling_Vaihingen/top/top_mosaic_09cm_area{{}}.tif\"\nLABEL_FILES = f\"{DATA_ROOT}/ISPRS_semantic_labeling_Vaihingen/gts_for_participants/top_mosaic_09cm_area{{}}.tif\"\n\n# Class labels\nLABELS = [\"roads\", \"buildings\", \"low veg.\", \"trees\", \"cars\", \"clutter\"]\nN_CLASSES = len(LABELS)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 4: Import Required Modules\nfrom dataset.dataset import ISPRS_dataset\nfrom utils.utils_dataset import convert_from_color, convert_to_color, disk, conn_comp\nfrom utils.utils import metrics, sliding_window, count_sliding_window, grouper\nfrom utils.export_result import set_output_location, export_results\nfrom net.net import CRFNet\nfrom net.loss import CrossEntropy2d\nfrom skimage import io\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport cv2\nfrom utils.utils_network import compute_class_weight\nfrom net.test_network import test\n\nprint(\"Imported all required modules\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 5: Function to analyze sparsity level of generated ground truth\ndef analyze_sparsity(gt_type, disk_size, sample_id=None):\n    \"\"\"\n    Analyze the sparsity level achieved with a given disk size\n    \n    Args:\n        gt_type: Type of ground truth (\"full\", \"conncomp\", \"ero\")\n        disk_size: Size of the erosion disk\n        sample_id: Sample ID to analyze (defaults to first training ID)\n    \n    Returns:\n        Percentage of labeled pixels\n    \"\"\"\n    if sample_id is None:\n        sample_id = train_ids[0]\n    \n    # Load a sample ground truth image\n    sample_gt = io.imread(LABEL_FILES.format(sample_id))\n    \n    # Convert to label format\n    sample_gt_labels = convert_from_color(sample_gt)\n    \n    # Apply appropriate function based on gt_type\n    if gt_type == \"full\":\n        sample_gt_processed = sample_gt_labels\n    elif gt_type == \"conncomp\":\n        sample_gt_processed = conn_comp(sample_gt_labels, disk(disk_size))\n    else:  # ero\n        sample_gt_processed = erode_gt(sample_gt_labels, disk(disk_size))\n    \n    # Count percentage of labeled pixels\n    total_valid_pixels = np.sum(sample_gt_labels != 6)  # Exclude already unlabeled pixels\n    labeled_pixels = np.sum((sample_gt_processed != 6) & (sample_gt_labels != 6))\n    \n    sparse_percentage = (labeled_pixels / total_valid_pixels) * 100\n    \n    return sparse_percentage, sample_gt_labels, sample_gt_processed","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 6: Function to find optimal disk size for target sparsity\ndef find_optimal_disk_size(gt_type, target_percentage, min_disk=1, max_disk=20):\n    \"\"\"\n    Find the optimal disk size to achieve a target percentage of labeled pixels\n    \n    Args:\n        gt_type: Type of ground truth (\"conncomp\", \"ero\")\n        target_percentage: Target percentage of labeled pixels\n        min_disk: Minimum disk size to try\n        max_disk: Maximum disk size to try\n    \n    Returns:\n        Best disk size\n    \"\"\"\n    best_disk_size = min_disk\n    best_difference = float('inf')\n    \n    results = []\n    \n    for disk_size in range(min_disk, max_disk + 1):\n        percentage, _, _ = analyze_sparsity(gt_type, disk_size)\n        difference = abs(percentage - target_percentage)\n        \n        results.append((disk_size, percentage, difference))\n        \n        if difference < best_difference:\n            best_difference = difference\n            best_disk_size = disk_size\n    \n    # Print results table\n    print(f\"Disk Size | Labeled % | Difference from {target_percentage}%\")\n    print(\"-\" * 50)\n    for disk_size, percentage, difference in results:\n        print(f\"    {disk_size:<5} | {percentage:7.2f}% | {difference:7.2f}%\")\n    \n    return best_disk_size","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 7: Define Training Function\ndef train_model(net, optimizer, scheduler, train_loader, epochs, save_epoch, weights, output_path):\n    \"\"\"\n    Train the CRFNet model with proper loss function implementation\n    \"\"\"\n    # Initialize loss tracking\n    max_iterations = epochs * len(train_loader)\n    losses = np.zeros(max_iterations)\n    mean_losses = np.zeros(max_iterations)\n    iter_ = 0\n    \n    # Training loop\n    for e in tqdm(range(1, epochs + 1), desc=\"Epochs\"):\n        # Set model to training mode\n        net.train()\n        \n        # Process each batch\n        for batch_idx, (data, target) in enumerate(tqdm(train_loader, desc=f\"Epoch {e}\", leave=False)):\n            # Process targets for multi-scale supervision\n            target_np = target.data.cpu().numpy()\n            target_np = np.transpose(target_np, [1, 2, 0])\n            \n            # Create multi-scale targets for different decoder outputs\n            target3 = np.transpose(cv2.resize(target_np, dsize=(128, 128), interpolation=cv2.INTER_NEAREST), [2, 0, 1])\n            target2 = np.transpose(cv2.resize(target_np, dsize=(64, 64), interpolation=cv2.INTER_NEAREST), [2, 0, 1])\n            target1 = np.transpose(cv2.resize(target_np, dsize=(32, 32), interpolation=cv2.INTER_NEAREST), [2, 0, 1])\n            target_np = np.transpose(target_np, [2, 0, 1])\n            \n            # Move data to device\n            if torch.cuda.is_available():\n                data = Variable(data.cuda())\n                target = Variable(torch.from_numpy(target_np).cuda())\n                target1_tensor = Variable(torch.from_numpy(target1).type(torch.LongTensor).cuda())\n                target2_tensor = Variable(torch.from_numpy(target2).type(torch.LongTensor).cuda())\n                target3_tensor = Variable(torch.from_numpy(target3).type(torch.LongTensor).cuda())\n            else:\n                data = Variable(data)\n                target = Variable(torch.from_numpy(target_np))\n                target1_tensor = Variable(torch.from_numpy(target1).type(torch.LongTensor))\n                target2_tensor = Variable(torch.from_numpy(target2).type(torch.LongTensor))\n                target3_tensor = Variable(torch.from_numpy(target3).type(torch.LongTensor))\n            \n            # Zero gradients\n            optimizer.zero_grad()\n            \n            # Forward pass - get all outputs\n            output, out_fc, out_neigh, _ = net(data)\n            \n            # Calculate multi-scale losses as described in the paper\n            # 1. Unary loss from main output\n            loss = CrossEntropy2d(output, target, weight=weights)\n            \n            # 2. Multi-scale supervision losses\n            if torch.cuda.is_available():\n                loss_fc1 = CrossEntropy2d(out_fc[0], target1_tensor, weight=compute_class_weight(target1).cuda())\n                loss_fc2 = CrossEntropy2d(out_fc[1], target2_tensor, weight=compute_class_weight(target2).cuda())\n                loss_fc3 = CrossEntropy2d(out_fc[2], target3_tensor, weight=compute_class_weight(target3).cuda())\n            else:\n                loss_fc1 = CrossEntropy2d(out_fc[0], target1_tensor, weight=compute_class_weight(target1))\n                loss_fc2 = CrossEntropy2d(out_fc[1], target2_tensor, weight=compute_class_weight(target2))\n                loss_fc3 = CrossEntropy2d(out_fc[2], target3_tensor, weight=compute_class_weight(target3))\n            \n            # 3. Pairwise potential loss from neighborhood layer\n            pairwise_loss = CrossEntropy2d(out_neigh, target, weight=weights)\n            \n            # 4. Combine losses exactly as in the paper\n            # Unary loss is average of multi-scale losses plus pairwise loss\n            total_loss = (loss + loss_fc1 + loss_fc2 + loss_fc3) / 4 + pairwise_loss\n            \n            # Backward pass and optimization\n            total_loss.backward()\n            optimizer.step()\n            \n            # Record loss\n            losses[iter_] = total_loss.item()\n            mean_losses[iter_] = np.mean(losses[max(0, iter_-100):iter_+1])\n            \n            # Display progress every 100 iterations\n            if iter_ % 100 == 0:\n                # Visualize results if desired\n                print(f'Epoch {e}/{epochs} [{batch_idx}/{len(train_loader)} ({100*batch_idx/len(train_loader):.0f}%)] Loss: {total_loss.item():.4f}')\n            \n            iter_ += 1\n        \n        # Update learning rate\n        scheduler.step()\n        \n        # Save model checkpoint\n        if e % save_epoch == 0:\n            model_path = f'{output_path}/model_epoch{e}.pth'\n            torch.save(net.state_dict(), model_path)\n            print(f\"Model saved to {model_path}\")\n    \n    # Save final model\n    final_model_path = f'{output_path}/model_final.pth'\n    torch.save(net.state_dict(), final_model_path)\n    print(f\"Final model saved to {final_model_path}\")\n    return final_model_path","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 8: Define Testing Function\ndef test_model(net, test_ids, data_files, label_files, labels, stride, batch_size, window_size, output_path=None):\n    \"\"\"\n    Test the model on the provided test data\n    \"\"\"\n    # Load test data\n    test_images = [1/255 * np.asarray(io.imread(data_files.format(id)), dtype='float32') for id in test_ids]\n    test_labels = [np.asarray(io.imread(label_files.format(id)), dtype='uint8') for id in test_ids]\n    eroded_labels = [convert_from_color(label) for label in test_labels]\n    \n    # Run the test\n    acc, all_preds, all_gts = test(\n        net, test_ids, test_images, test_labels, eroded_labels, \n        labels, stride, batch_size, window_size=window_size, all=True\n    )\n    \n    # Export results\n    if output_path:\n        title = \"Quantitative results for CRFNet testing\"\n        export_results(\n            all_preds, all_gts, \n            os.path.dirname(output_path), os.path.basename(output_path),\n            confusionMat=True,\n            prodAccuracy=True,\n            averageAccuracy=True,\n            kappaCoeff=True,\n            title=title\n        )\n        \n        # Save prediction images\n        for pred, tile_id in zip(all_preds, test_ids):\n            img = convert_to_color(pred)\n            io.imsave(f\"{output_path}/segmentation_result_area{tile_id}.png\", img)\n    \n    return acc, all_preds, all_gts","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 9: Define experiment runner function for different sparsity levels\ndef run_experiment(gt_type, gt_percentage=None, disk_size=None):\n    \"\"\"\n    Run a complete training and testing cycle for a specific ground truth configuration\n    \n    Parameters:\n    gt_type - Type of ground truth: 'full', 'conncomp', 'ero'\n    gt_percentage - For 'conncomp' or 'ero', the percentage of labeled pixels (10 or 30)\n    disk_size - Size of erosion disk, if None will be determined automatically\n    \"\"\"\n    # Use default disk size if not specified\n    if disk_size is None:\n        if gt_type == 'full':\n            disk_size = ERO_DISK_SIZE  # Default, but not used for full GT\n        elif gt_percentage == 30:\n            disk_size = 8  # Default size for 30% sparsity (experimentally determined)\n        elif gt_percentage == 10:\n            disk_size = 12  # Default size for 10% sparsity (experimentally determined)\n        else:\n            disk_size = ERO_DISK_SIZE\n    \n    # Create experiment name\n    if gt_type == 'full':\n        experiment_name = f\"CRFNet_{DATASET_TYPE}_full_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n    else:\n        experiment_name = f\"CRFNet_{DATASET_TYPE}_{gt_type}_{gt_percentage}pct_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n    \n    # Create experiment directory\n    os.makedirs(f\"{OUTPUT_ROOT}/{experiment_name}\", exist_ok=True)\n    \n    print(f\"Starting experiment: {experiment_name}\")\n    print(f\"Dataset: {DATASET_TYPE}\")\n    print(f\"Ground Truth Type: {gt_type}\")\n    if gt_type != 'full':\n        print(f\"Target Sparse GT percentage: {gt_percentage}%\")\n        print(f\"Using disk size: {disk_size}\")\n    \n    # Analyze and display actual sparsity level\n    if gt_type != 'full':\n        actual_percentage, _, _ = analyze_sparsity(gt_type, disk_size)\n        print(f\"Actual labeled percentage: {actual_percentage:.2f}%\")\n    \n    # Initialize the CRFNet model\n    net = CRFNet(n_channels=IN_CHANNELS, n_classes=N_CLASSES, bilinear=True)\n    \n    # Setup optimizer and learning rate scheduler\n    optimizer = optim.SGD(net.parameters(), lr=BASE_LR, momentum=0.9, weight_decay=WEIGHT_DECAY)\n    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [25, 35, 45], gamma=0.1)\n    \n    # Move model to GPU if available\n    if torch.cuda.is_available():\n        net.cuda()\n        weights = torch.ones(N_CLASSES).cuda()\n    else:\n        weights = torch.ones(N_CLASSES)\n    \n    # Create dataset with correct ground truth processing\n    train_set = ISPRS_dataset(\n        ids=train_ids,\n        ids_type='TRAIN',\n        gt_type=gt_type,\n        gt_modification=disk(disk_size),\n        data_files=DATA_FILES,\n        label_files=LABEL_FILES,\n        window_size=WINDOW_SIZE,\n        cache=True,\n        augmentation=True\n    )\n    \n    # Create data loader\n    train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE)\n    print(f\"Created training loader with approximately {len(train_set) // BATCH_SIZE} batches per epoch\")\n    \n    # Train the model\n    print(\"Starting model training...\")\n    model_path = train_model(\n        net=net,\n        optimizer=optimizer,\n        scheduler=scheduler,\n        train_loader=train_loader,\n        epochs=EPOCHS,\n        save_epoch=SAVE_EPOCH,\n        weights=weights,\n        output_path=f\"{OUTPUT_ROOT}/{experiment_name}\"\n    )\n    print(f\"Training completed! Model saved to {model_path}\")\n    \n    # Test the model\n    print(\"Starting model testing...\")\n    accuracy, all_preds, all_gts = test_model(\n        net=net,\n        test_ids=test_ids,\n        data_files=DATA_FILES,\n        label_files=LABEL_FILES,\n        labels=LABELS,\n        stride=STRIDE,\n        batch_size=BATCH_SIZE,\n        window_size=WINDOW_SIZE,\n        output_path=f\"{OUTPUT_ROOT}/{experiment_name}\"\n    )\n    \n    print(f\"Testing completed with overall accuracy: {accuracy:.2f}%\")\n    \n    # Create a visualization of all test results\n    n_images = len(test_ids)\n    fig, axes = plt.subplots(n_images, 3, figsize=(15, 5*n_images))\n    \n    for i, (id, pred, gt) in enumerate(zip(test_ids, all_preds, all_gts)):\n        # Load original image\n        img = 1/255 * np.asarray(io.imread(DATA_FILES.format(id)), dtype='float32')\n        \n        # Display original image, ground truth, and prediction\n        if n_images > 1:\n            axes[i, 0].imshow(np.asarray(255 * img, dtype='uint8'))\n            axes[i, 0].set_title(f'Area {id} - Original')\n            axes[i, 1].imshow(convert_to_color(gt))\n            axes[i, 1].set_title('Ground Truth')\n            axes[i, 2].imshow(convert_to_color(pred))\n            axes[i, 2].set_title('Prediction')\n        else:\n            axes[0].imshow(np.asarray(255 * img, dtype='uint8'))\n            axes[0].set_title(f'Area {id} - Original')\n            axes[1].imshow(convert_to_color(gt))\n            axes[1].set_title('Ground Truth')\n            axes[2].imshow(convert_to_color(pred))\n            axes[2].set_title('Prediction')\n    \n    plt.tight_layout()\n    plt.savefig(f\"{OUTPUT_ROOT}/{experiment_name}/all_results.png\", dpi=300, bbox_inches='tight')\n    plt.close()\n    \n    print(f\"Results visualization saved to {OUTPUT_ROOT}/{experiment_name}/all_results.png\")\n    \n    # Return experiment results\n    return {\n        'experiment_name': experiment_name,\n        'accuracy': accuracy,\n        'model_path': model_path,\n        'predictions': all_preds\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 10: Visualize sparsity levels for different disk sizes\n# This cell will help determine the right disk sizes for 10% and 30% sparsity\nprint(\"Analyzing sparsity levels for different disk sizes...\")\n# Try disk sizes from 4 to 16\nsparsity_results = []\nfor disk_size in range(4, 17, 2):\n    percentage, _, _ = analyze_sparsity(\"conncomp\", disk_size)\n    sparsity_results.append((disk_size, percentage))\n    print(f\"Disk size {disk_size}: {percentage:.2f}% labeled pixels\")\n\n# Plot the results\nplt.figure(figsize=(10, 6))\ndisk_sizes, percentages = zip(*sparsity_results)\nplt.plot(disk_sizes, percentages, 'o-', linewidth=2)\nplt.axhline(y=30, color='r', linestyle='--', label='30% Target')\nplt.axhline(y=10, color='g', linestyle='--', label='10% Target')\nplt.xlabel('Disk Size')\nplt.ylabel('Percentage of Labeled Pixels')\nplt.title('Sparsity Level vs Disk Size')\nplt.grid(True)\nplt.legend()\nplt.show()\n\n# Find optimal disk sizes for 10% and 30% sparsity\ndisk_size_30pct = find_optimal_disk_size(\"conncomp\", 30)\ndisk_size_10pct = find_optimal_disk_size(\"conncomp\", 10)\n\nprint(f\"Recommended disk size for 30% sparsity: {disk_size_30pct}\")\nprint(f\"Recommended disk size for 10% sparsity: {disk_size_10pct}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 11: Run all three experiments\nresults = {}\n\n# 1. Full ground truth experiment\nprint(\"=\" * 80)\nprint(\"RUNNING EXPERIMENT 1/3: FULL GROUND TRUTH\")\nprint(\"=\" * 80)\nresults['full'] = run_experiment(gt_type='full')\n\n# 2. 30% ground truth experiment\nprint(\"\\n\" + \"=\" * 80)\nprint(\"RUNNING EXPERIMENT 2/3: 30% GROUND TRUTH\")\nprint(\"=\" * 80)\nresults['30pct'] = run_experiment(gt_type='conncomp', gt_percentage=30, disk_size=disk_size_30pct)\n\n# 3. 10% ground truth experiment\nprint(\"\\n\" + \"=\" * 80)\nprint(\"RUNNING EXPERIMENT 3/3: 10% GROUND TRUTH\")\nprint(\"=\" * 80)\nresults['10pct'] = run_experiment(gt_type='conncomp', gt_percentage=10, disk_size=disk_size_10pct)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 12: Print summary and create comparison chart\nprint(\"\\n\" + \"=\" * 80)\nprint(\"EXPERIMENT RESULTS SUMMARY\")\nprint(\"=\" * 80)\nprint(f\"Full GT: {results['full']['accuracy']:.2f}%\")\nprint(f\"30% GT: {results['30pct']['accuracy']:.2f}%\")\nprint(f\"10% GT: {results['10pct']['accuracy']:.2f}%\")\nprint(\"=\" * 80)\n\n# Create a bar chart comparing the results\nplt.figure(figsize=(10, 6))\nlabels = ['Full GT', '30% GT', '10% GT']\nvalues = [results['full']['accuracy'], results['30pct']['accuracy'], results['10pct']['accuracy']]\nplt.bar(labels, values, color=['green', 'blue', 'orange'])\nplt.axhline(y=85, color='r', linestyle='--', label='Paper 30% Result')\nplt.axhline(y=81, color='purple', linestyle='--', label='Paper 10% Result')\nplt.axhline(y=90, color='green', linestyle='--', label='Paper Full Result')\nplt.ylabel('Overall Accuracy (%)')\nplt.title('CRFNet Performance on Vaihingen Dataset')\nplt.legend()\nplt.grid(axis='y', alpha=0.3)\nplt.savefig(f\"{OUTPUT_ROOT}/accuracy_comparison.png\", dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"All experiments completed successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}